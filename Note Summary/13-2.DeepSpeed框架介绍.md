# DeepSpeed框架介绍

<p align="right">2026.02.23</p>

## 1. DeepSpeed 核心定位与模块

### 1.1. 核心目标

解决大模型训练的三大痛点：**显存不足、加速比不理想、硬件异构资源利用率低**，实现“**更少显存训练更大模型、训练更快、扩展更稳**”，覆盖从训练到推理的全流程工程化优化。

### 1.2. 与 Hugging Face 关系
- Hugging Face：聚焦“模型与数据”生态（transformers、datasets 等）；
- DeepSpeed：聚焦“**系统与算力**”生态（显存优化、并行策略、通信调度等）。

### 1.3. 核心子模块

|模块|核心功能|典型场景|
|---|---|---|
|DeepSpeed Training|ZeRO 系列、3D 并行等训练优化|单机/多机多卡预训练/全量微调|
|DeepSpeed Inference|推理 Kernel、KV Cache、量化/剪枝优化|高吞吐推理服务部署|
|DeepSpeed-MoE|MoE 大模型高效路由与通信|MoE 模型训练|
|DeepSpeed-Chat/RLHF|大规模 RLHF 训练流水线，集成 ZeRO/并行策略|对话模型对齐训练|
|DeepSpeed for Science|稀疏算子、科学计算结构优化，迁移 LLM 训练经验|分子模拟、气候建模等科学计算|

## 2. 显存开销与 ZeRO 系列核心优化

### 2.1. 全量训练显存开销（以 7B 模型为例）

经典**数据并行+Adam 优化器**下，单参数显存占用约 16 Bytes（不含激活/碎片）：
- 模型权重（FP16/BF16）：2 Bytes/参数 → 7B 模型约 14GB；
- 梯度（FP16/BF16）：2 Bytes/参数 → 7B 模型约 14GB；
- 优化器状态（Adam，FP32）：12 Bytes/参数 → 7B 模型约 84GB；
- 总开销（不含激活）：112GB，实际峰值可达 120GB+。

### 2.2. ZeRO（Zero Redundancy Optimizer）核心思路

将模型状态（**优化器状态、梯度、参数**）在多卡间**分片存储**，消除数据并行的冗余复制，降低单卡显存压力。

### 2.3. ZeRO 三个核心阶段

|阶段|分片对象|单卡显存公式（相对规模）|每参数显存（16 Bytes 拆解）|核心收益|
|---|---|---|---|---|
|基线（DP）|无（全量复制）|$Mem ∝ P + G + OS$|2+2+12=16 Bytes|无|
|ZeRO-1|仅优化器状态（OS）|$Mem ∝ P + G + OS/DP$|2+2+12/DP|显存节省 ~75%（OS 占比最大）|
|ZeRO-2|OS + 梯度（G）|$Mem ∝ P + G/DP + OS/DP$|2+(2+12)/DP|显存节省 8~16 倍（视 DP 而定）|
|ZeRO-3|OS + G + 参数（P）|$Mem ∝ (P+G+OS)/DP$|(2+2+12)/DP=16/DP|单卡显存随 GPU 数 1/DP 降低|

示例：DP=64 时，ZeRO-3 可将每参数显存压缩至 ~0.25 Bytes，支持 64 张 V100 训练万亿参数模型。

### 2.4. ZeRO 补充优化

（1）**ZeRO-R：解决非核心显存瓶颈**

- **分区激活检查点**：消除模型并行中激活值冗余，显存随 MP 线性降低；
- **恒定大小缓冲区**：减少显存碎片；
- **显存碎片整理**：保持长训练过程的可用显存比例。

（2）**ZeRO-Offload：GPU ↔ CPU 内存协同**

- 核心：**将 FP32 优化器状态/梯度卸载到 CPU 内存，GPU 聚焦前向/反向计算**；
- 关键机制：**单步延迟更新（DPU）**，CPU 参数更新与 GPU 下一轮计算重叠，掩盖延迟；
- **多卡优化**：先梯度分片（Reduce-Scatter）再 Offload，控制 CPU-GPU 交换开销。

（3）**ZeRO-Infinity：突破显存墙（GPU+CPU+NVMe）**

- **异构存储体系**：GPU HBM（Fast）→ CPU DRAM（Medium）→ NVMe SSD（Slow）；
- 核心策略：
    - **带宽为中心切分**：多卡并行 All-Gather 拉取数据，聚合带宽随 GPU 数线性增加；
    - **内存为中心切片**：拆解超大算子为 Tile，逐块计算，降低对张量并行的刚性依赖；
- 扩展性：单 DGX-2（16 张 V100）可微调 1 万亿参数模型，512 张 GPU 支持 32 万亿参数训练。

### 2.5. ZeRO 通信开销
- ZeRO-1/2：通信量 2Ψ（与标准 DP 同阶）；
- ZeRO-3：通信量 3Ψ（约 DP 的 1.5 倍），但显存收益远大于通信成本，且更大 Batch Size 可提升计算效率。

## 3. DeepSpeed 并行策略体系

### 3.1. 四类核心并行策略

|并行类型|核心逻辑|优缺点|
|---|---|---|
|**数据并行（DP）**|**多卡复制完整模型**，处理不同数据子集，All-Reduce 汇总梯度|优点：实现简单、易扩展；缺点：单卡显存开销大（ZeRO 针对性优化）|
|**张量并行（TP）**|**单层算子（如矩阵乘法）按维度拆分到多卡**，协作计算|优点：突破单卡显存限制；缺点：通信频繁、对跨节点带宽敏感|
|**流水线并行（PP）**|**模型按层切分**，多卡按“流水线”处理不同层段，配合 Micro-batch 减少空转|优点：适配深层模型；缺点：需优化 Micro-batch 大小，减少“气泡”等待|
|**3D 并行**|**DP × TP × PP 组合使用**|优点：支撑超大规模模型训练（如 BLOOM 176B）；缺点：调度复杂度高|

### 3.2. 并行策略配合逻辑

- DP 解决“更多数据”问题；
- TP/PP 解决“更大模型”问题；
- ZeRO/Offload/Infinity 解决“显存不足 & 异构资源利用”问题。

> 总结：
> 1. DeepSpeed 核心是通过 ZeRO 系列分片+Offload 技术，将单卡显存压力从“全量承担”转为“多卡/异构资源分摊”；
> 2. ZeRO 阶段越高，显存节省越显著，但通信开销略有增加，工程上需平衡显存与通信；
> 3. 3D 并行 + ZeRO-Infinity 是超大规模（万亿级）模型训练的核心组合；
> 4. 不同场景选型：
    > - 单机多卡全量微调：ZeRO-2 + 少量 TP；
    > - 万亿参数训练：ZeRO-3 + 3D 并行 + ZeRO-Infinity；
    > - 推理部署：DeepSpeed-Inference + 量化/剪枝。